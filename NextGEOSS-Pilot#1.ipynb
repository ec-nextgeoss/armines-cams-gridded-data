{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:31:44.954118Z",
     "start_time": "2019-01-14T14:31:44.942801Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "PATH = \"./img/\"\n",
    "Image(filename = PATH + \"NextGEOSS-Logo.png\", width=512, height=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Introduction to NextGEOSS Energy Pilot. (README First !)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Access time series of gridded data from CAMS Radiation\n",
    "\n",
    "### This pilot allows to requests for time-series of solar radiation over a regular grid of points covering area of interest (AOI).\n",
    "\n",
    "#### GEOGRAPHICAL AREA\n",
    "\n",
    "Geographical coverage of the CAMS radiation product is the field-of-view of the Meteosat satellite, roughly speaking Europe, Africa, Atlantic Ocean, Middle East (-66° to 66° in both latitudes and longitudes).\n",
    "\n",
    "#### DATA\n",
    "\n",
    "The data you request come from CAMS (Copernicus Atmosphere Monitoring Service) Radiation product from a two years time period including the following parameters (Atmosphere optical properties, Ground reflectance, Cloud optical properties, Atmosphere radiative transfer). **#IMPORTANT NOTE: ONLY THE YEARS 2005 AND 2006 ARE CURRENTLY AVAILABLE FOR THIS PILOT#**\n",
    "\n",
    "#### HOW TO REQUEST THE DATA\n",
    "\n",
    "The request to the data is made using an **OGC (Open Geospatial Consortium)** standard Web service called **WPS (Web Processing Service)**. This WPS is located remotely on a cloud server and provided as an asynchronous request to the CAMS Radiation process in order to deliver time series of gridded data on selected AOI.\n",
    "\n",
    "The parameters are first encoded in an url and sent to the Cloud as a WPS request. \n",
    "\n",
    "This notebook will first demonstrate how to build the first url. It will then provide a set of command that fully automate the subsequent \"treasure hunt\" up to the downloading of the data.\n",
    "\n",
    "#### HOW TO USE THE DATA\n",
    "\n",
    "Once downloaded as an HDF5 encode file, the Notebook provides you with several results displays:\n",
    "* An animated display of the various time frame layers\n",
    "* A use case where a time-series of a single is point is compared to an average of gridded data over a given region (NUTS-3 shape)\n",
    "* A use case where a time-series of a single is point is compared to an average of gridded data over a given geometrical AOI (Area Of Interest)\n",
    "\n",
    "**Please allow some time for data to be processed and downloaded. When done you'll have a preview of your time series of gridded data at the bottom of the page. The following example retrieve a full day every 15 mn. from 00:15 providing you with 96 layers over an AOI covering France**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needed libraries: (Optional reading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code cells, you'll find various libraries that are needed in order to ensure the pilot to properly run the code and display the results. As a sum-up from a scratch installation you'll need to install the following libraries:\n",
    "* conda install shapely \n",
    "* conda install geopandas\n",
    "* conda install numpy\n",
    "* conda install cartopy\n",
    "* conda install nodejs\n",
    "* conda install ipywidgets\n",
    "* conda install h5py\n",
    "* conda install matplotlib\n",
    "* conda install urllib3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:28:38.384070Z",
     "start_time": "2019-01-14T14:28:37.844983Z"
    }
   },
   "outputs": [],
   "source": [
    "import re, time\n",
    "from collections import OrderedDict\n",
    "\n",
    "# some GUI Elements\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import ipywidgets as wdg\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, DrawControl, GeoJSON\n",
    "\n",
    "# Usuall data analysis\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# To read xml files\n",
    "import xml.etree.ElementTree as xml\n",
    "\n",
    "# To download data\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "class value_handler:\n",
    "    def __init__(self, key, long_name, value):\n",
    "        self.key = key\n",
    "        self.long_name = long_name\n",
    "        self.value = value\n",
    "\n",
    "class value_handler_flt(value_handler):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__(*args)\n",
    "    def from_str(self, value):\n",
    "        self.value = float(value)\n",
    "\n",
    "class value_handler_int(value_handler):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__(*args)\n",
    "    def from_str(self, value):\n",
    "        self.value = int(value)\n",
    "\n",
    "class value_handler_str(value_handler):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__(*args)\n",
    "    def from_str(self, value):\n",
    "        self.value = str(value)\n",
    "        \n",
    "def make_circle(center, radius, rez):\n",
    "    angles = np.linspace(0.0, 2*np.pi, rez)\n",
    "    x = np.cos(angles)*radius+center[0]\n",
    "    y = np.sin(angles)*radius+center[1]\n",
    "    return np.vstack((y[::-1], x[::-1])).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace = {\n",
    "    'wps': 'http://www.opengis.net/wps/1.0.0',\n",
    "    'ows': 'http://www.opengis.net/ows/1.1',\n",
    "    'mlk': 'http://www.metalinker.org/'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Encoding the request in a url: (Optional reading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "The first url is the only wat you need to worry about, as it is where you define the particulars of your request (inputs, methods, outputs etc). \n",
    "\n",
    "**Url decomposition**\n",
    "The url can be decomposed in 4 parts:\n",
    "* The 'base string' defines the requested service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T13:13:52.365595Z",
     "start_time": "2018-10-23T13:13:52.363493Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# release server\n",
    "base_str = 'http://gridded-data.armines.nextgeoss.terradue.com/wps/WebProcessingService?service=wps&version=1.0.0&request=Execute&identifier=com.terradue.wps_oozie.process.OozieAbstractAlgorithm&'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* The inputs string sets the parameters of the request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T13:13:52.369705Z",
     "start_time": "2018-10-23T13:13:52.367374Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#input_str = 'dataInputs=bbox=-5.0,46.0,6.0,45.0;width=300;height=300;datex=2453385.510416666666;dt=0.010441666666;count=96;min_tile_width=100;min_tile_height=100;&'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* The output string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T13:13:52.374009Z",
     "start_time": "2018-10-23T13:13:52.371612Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output_str = 'ResponseDocument=result_distribution@mimeType=application/xml;result_osd@mimeType=application/xml&storeExecuteResponse=true&status=true'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The final url is the aggregation of the 4 parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T13:13:52.378396Z",
     "start_time": "2018-10-23T13:13:52.375417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#url_request = base_str+input_str+output_str\n",
    "#print(url_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the input parameters here: !!! (README)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "While it is possible to manually modify the url, simple python functions can make WPS more flexible. \n",
    "The input parameters can be specified by changing the value in <font color='green'>green</font>. In the default example we've selected an AOI (Area Of Interest) covering France with a 300x300 resolution for one day (Saturday 2005 Jan) starting at 00:15h every 15 minutes resulting in HDF file of 96 layers This includes:\n",
    "* **left_lon** (Left side of a bounding box longitude wise in degree - default is -5.5)\n",
    "* **top_lat** (Top side of a bounding box latitude wise in degree - default is 51.3)\n",
    "* **right_lon** (Right side of a bounding box longiture wise in degree - default is 8.5)\n",
    "* **bot_lat** (Bottom size of a bounding box latitude wise in degree - default is 41.0)\n",
    "* **width** (Size in pixel of the width of the result map - default is 300)\n",
    "* **height** (Size in pixel of the height of the result map - default is 300)\n",
    "* **datex** (Begin date in Julian date - default is 2005 Jun 22 at 00:15)\n",
    "* **dt** (Time span for the number of occurence in Julian time - default is 15 mn)\n",
    "* **count** (Number of occurence in the time serie of gridded data - default is 96 (Covers 1 day every 15 mn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise inputs to default value if not already created\n",
    "if \"inputs\" not in globals():\n",
    "    inputs = OrderedDict([\n",
    "        (\"bot_lat\",       value_handler_flt(\"bot_lat\", \"Latitude at bottom\", 41.0)),\n",
    "        (\"top_lat\",       value_handler_flt(\"top_lat\", \"Latitude at top\", 51.3)),\n",
    "        (\"left_lon\",      value_handler_flt(\"left_lon\", \"Longitude at left\", -5.5)),\n",
    "        (\"right_lon\",     value_handler_flt(\"right_lon\", \"Longitude at right\", 8.5)),\n",
    "        (\"width\",         value_handler_int(\"width\", \"Output width\", 300)),\n",
    "        (\"height\",        value_handler_int(\"height\", \"Output height\", 300)),\n",
    "        (\"first_instant\", value_handler_str(\"first_instant\", \"First instant of the time-series\", '2005-06-22 00:15')),\n",
    "        (\"dt\",            value_handler_flt(\"dt\", \"Interval between instants in minute(s)\", 15)),\n",
    "        (\"count\",         value_handler_int(\"count\", \"Number of instant\", 96))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "map_context = {\n",
    "    'url': 'http://tiles.osm.webservice-energy.org/osm/{z}/{x}/{y}.png',\n",
    "    'attribution': '<a href=\"https://www.openstreetmap.org/copyright\">OpenStreeMap</a>',\n",
    "    'name': 'openstreetmap',\n",
    "    'max_zoom': 9\n",
    "}\n",
    "\n",
    "m = Map(center=(30.0, 0.0), zoom=2, layout={'width': '600px', 'height': '300px'})\n",
    "openstreetmap_layer = basemap_to_tiles(map_context)\n",
    "m.add_layer(openstreetmap_layer)\n",
    "\n",
    "available_area = GeoJSON(data={\n",
    "            'type': 'Feature', \n",
    "        'properties': {\n",
    "            'style': {\n",
    "                'stroke': True, \n",
    "                'color': '#00ff00', \n",
    "                'weight': 1, \n",
    "                'opacity': 0.5,\n",
    "                'fill': True, \n",
    "                'fillColor': None, \n",
    "                'fillOpacity': 0.05, \n",
    "                'showArea': True, \n",
    "                'clickable': False\n",
    "            }\n",
    "        }, \n",
    "        'geometry': {\n",
    "            'type': 'Polygon', \n",
    "            'coordinates':  [ make_circle((0.0, 0.0), 60.0, 100).tolist() ]\n",
    "        }\n",
    "})\n",
    "\n",
    "m.add_layer(available_area)\n",
    "\n",
    "\n",
    "def update_current_bbox():\n",
    "    global current_bbox, m, inputs\n",
    "    \n",
    "    try:\n",
    "        m.remove_layer(current_bbox)\n",
    "        current_bbox = None\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    current_bbox = GeoJSON(data={\n",
    "        'type': 'Feature', \n",
    "        'properties': {\n",
    "            'style': {\n",
    "                'stroke': True, \n",
    "                'color': '#ff0000', \n",
    "                'weight': 4, \n",
    "                'opacity': 0.5, \n",
    "                'fill': True, \n",
    "                'fillColor': None, \n",
    "                'fillOpacity': 0.2, \n",
    "                'showArea': True, \n",
    "                'clickable': True\n",
    "            }\n",
    "        }, \n",
    "        'geometry': {\n",
    "            'type': 'Polygon', \n",
    "            'coordinates': [\n",
    "                [[inputs['left_lon'].value,  inputs['bot_lat'].value], \n",
    "                 [inputs['left_lon'].value,  inputs['top_lat'].value], \n",
    "                 [inputs['left_lon'].value,  inputs['top_lat'].value], \n",
    "                 [inputs['right_lon'].value, inputs['top_lat'].value], \n",
    "                 [inputs['right_lon'].value, inputs['bot_lat'].value]]\n",
    "            ]\n",
    "        }\n",
    "    })\n",
    "\n",
    "    m.add_layer(current_bbox)\n",
    "\n",
    "update_current_bbox()\n",
    "\n",
    "wdgs = {}\n",
    "for xp in inputs.values():\n",
    "    l = wdg.Label(xp.long_name, layout={'width': '150px'})\n",
    "    t = (wdg.Text(value=str(xp.value), layout={'width': '150px'}))\n",
    "    if xp.key in {\"left_lon\", \"right_lon\", \"bot_lat\", \"top_lat\"}:\n",
    "        def on_change(x, xp=xp):\n",
    "            xp.from_str(x['new'])\n",
    "            update_current_bbox()\n",
    "    else:\n",
    "        def on_change(x, xp=xp):\n",
    "            xp.from_str(x['new'])\n",
    "            \n",
    "    t.observe(on_change, names='value')\n",
    "    wdgs[xp.key] = wdg.HBox([l, t])\n",
    "    \n",
    "def xdraw(dc, action, geo_json):\n",
    "    global m, current_bbox\n",
    "    dc.clear()    \n",
    "    # update inputs data\n",
    "    bbox = np.squeeze(np.array(geo_json['geometry']['coordinates']))\n",
    "    \n",
    "    wdgs[\"left_lon\"].children[1].value = str(np.min(bbox[:,0]))\n",
    "    wdgs[\"right_lon\"].children[1].value = str(np.max(bbox[:,0]))\n",
    "    wdgs[\"top_lat\"].children[1].value = str(np.max(bbox[:,1]))\n",
    "    wdgs[\"bot_lat\"].children[1].value = str(np.min(bbox[:,1]))\n",
    "\n",
    "dc = DrawControl(rectangle={'shapeOptions': {'color': '#ff0000'}}, circlemarker={}, polyline={}, polygon={}, edit=False, remove=False)\n",
    "dc.on_draw(xdraw)\n",
    "m.add_control(dc)\n",
    "print(\"Select an area using the rectangle tool\")\n",
    "\n",
    "display(m)\n",
    "\n",
    "layout = [\n",
    "        [\"width\",          \"left_lon\"],\n",
    "        [\"height\",         \"right_lon\"],\n",
    "        [\"first_instant\",  \"top_lat\"],\n",
    "        [\"dt\",             \"bot_lat\"],\n",
    "        [\"count\",          None]]\n",
    "\n",
    "display(wdg.VBox([wdg.HBox([wdgs[x] for x in l if x is not None]) for l in layout]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T17:33:01.431216Z",
     "start_time": "2019-01-14T17:33:01.426101Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display inputs in human-readble form,\n",
    "readable_input = pd.DataFrame([x.value for x in inputs.values()],columns=[''],dtype='object')\n",
    "readable_input.index = [x.long_name for x in inputs.values()]\n",
    "display(readable_input)\n",
    "\n",
    "# Translate input format WPS-appropriate format,\n",
    "wps_inputs = {x.key: x.value for x in inputs.values()}\n",
    "wps_inputs[\"first_instant\"] = pd.to_datetime(wps_inputs[\"first_instant\"]).to_julian_date()\n",
    "wps_inputs[\"dt\"] = wps_inputs['dt']/(60*24)\n",
    "\n",
    "input_str = 'dataInputs=bbox={left_lon:f},{top_lat:f},{right_lon:f},{bot_lat:f};width={width:d};height={height:d};datex={first_instant:f};dt={dt:f};count={count:d};tiles_factor_count=8;avg_tile_size=10000000&'\n",
    "input_str = input_str.format(**wps_inputs)\n",
    "print(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:28:42.175048Z",
     "start_time": "2019-01-14T14:28:41.999656Z"
    }
   },
   "outputs": [],
   "source": [
    "url_request = base_str+input_str+output_str\n",
    "print(url_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Parsing the query and request access to the data: (Optional reading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several steps are necessary to download the data. While they may seem somewhat cumbersome, once you have encoded your request in url_request you can simply run the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the request to the WPS server\n",
    "### Warning: this line launches a request. It should not be called several time !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:28:43.581888Z",
     "start_time": "2019-01-14T14:28:43.570041Z"
    }
   },
   "outputs": [],
   "source": [
    "# Warning: this line launches a request. It should not be called several time\n",
    "# r = PoolManager().request('GET', url_request)\n",
    "r = urlopen(url_request)\n",
    "tree = xml.fromstring(r.read().decode(\"utf-8\"))\n",
    "if not tree.tag == \"{http://www.opengis.net/wps/1.0.0}ExecuteResponse\":\n",
    "    raise Exception(\"Unexpected response\")\n",
    "if tree.find(\"./{http://www.opengis.net/wps/1.0.0}Status/{http://www.opengis.net/wps/1.0.0}ProcessAccepted\") is None:\n",
    "    raise Exception(\"Process was not accepted, please check your parameters\")\n",
    "status_url = tree.attrib[\"statusLocation\"]\n",
    "print(\"Process accepted with folowing status url:\")\n",
    "print(status_url)\n",
    "print(\"you do not need to run it again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait for the WPS response\n",
    "### The server response may be failed or Succeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:28:44.084287Z",
     "start_time": "2019-01-14T14:28:44.050809Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"please wait for the server\")\n",
    "\n",
    "p = wdg.FloatProgress(min=0, max=100, description='Waiting:')\n",
    "l = wdg.Label()\n",
    "display(wdg.HBox([p, l]))\n",
    "\n",
    "while True:\n",
    "    r = urlopen(status_url)\n",
    "    tree = xml.fromstring(r.read().decode(\"utf-8\"))\n",
    "    if not tree.tag == \"{http://www.opengis.net/wps/1.0.0}ExecuteResponse\":\n",
    "        Exception(\"Unexpected response\")\n",
    "    status = tree.find(\"./{http://www.opengis.net/wps/1.0.0}Status/*\")\n",
    "    if status.tag == \"{http://www.opengis.net/wps/1.0.0}ProcessFailed\":\n",
    "        error = status.find(\".//{http://www.opengis.net/ows/1.1}ExceptionText\")\n",
    "        raise Exception(\"WPS Process fail with error: %s\"%(error.text))\n",
    "    elif status.tag == \"{http://www.opengis.net/wps/1.0.0}ProcessStarted\":\n",
    "        p.value = int(status.attrib[\"percentCompleted\"])\n",
    "        l.value = \"%d%%\"%(p.value,)\n",
    "    elif status.tag == \"{http://www.opengis.net/wps/1.0.0}ProcessAccepted\":\n",
    "        pass\n",
    "    elif status.tag == \"{http://www.opengis.net/wps/1.0.0}ProcessPaused\":\n",
    "        print(\"Process paused\")\n",
    "    elif status.tag == \"{http://www.opengis.net/wps/1.0.0}ProcessSucceeded\":\n",
    "        p.value = 100\n",
    "        l.value = \"100%\"\n",
    "        break\n",
    "    time.sleep(10)\n",
    "print(\"Process succeeded\")\n",
    "# TODO: Get the result link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retreive the result from the WPS server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:28:44.409967Z",
     "start_time": "2019-01-14T14:28:44.395995Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = tree.findall(\"./wps:ProcessOutputs/wps:Output\", namespace)\n",
    "if outputs is None:\n",
    "    raise Exception(\"No outputs found!\")\n",
    "\n",
    "output_metalink = None\n",
    "for o in outputs:\n",
    "    identifier = o.find(\"./ows:Identifier\", namespace)\n",
    "    if identifier is None:\n",
    "        continue\n",
    "    if identifier.text == \"result_distribution\":\n",
    "        ref = o.find(\"./wps:Data/wps:ComplexData/wps:Reference\", namespace)\n",
    "        if ref is None:\n",
    "            raise Exception(\"No Reference link found!\")\n",
    "        output_metalink = ref.attrib['href']\n",
    "        \n",
    "if output_metalink is None:\n",
    "    raise Exception(\"Output reference link not found!\")\n",
    "\n",
    "r = urlopen(output_metalink)\n",
    "t = xml.fromstring(r.read().decode(\"utf-8\"))\n",
    "if t.tag != '{http://www.metalinker.org/}metalink':\n",
    "    raise Exception(\"Invalid metalink\")\n",
    "\n",
    "link = t.find(\"./mlk:files/mlk:file[@name='resultx.h5']/mlk:resources/mlk:url\", namespace)\n",
    "if link is None:\n",
    "    raise Exception(\"No result file url found!\")\n",
    "final_url = link.text\n",
    "\n",
    "link = t.find(\"./mlk:files/mlk:file[@name='meta.json']/mlk:resources/mlk:url\", namespace)\n",
    "if link is None:\n",
    "    raise Exception(\"No meta file url found!\")\n",
    "meta_url = link.text\n",
    "\n",
    "print(\"Result URL: \", final_url)\n",
    "print(\"Meta URL: \", meta_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download final data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:28:45.134460Z",
     "start_time": "2019-01-14T14:28:45.121035Z"
    }
   },
   "outputs": [],
   "source": [
    "r = urlopen(final_url)\n",
    "\n",
    "if 'content-length' in r.headers:\n",
    "    content_length = int(r.headers['content-length'])\n",
    "\n",
    "    print('Downloading %.1fMo:'%(content_length/1e6))\n",
    "    p = wdg.FloatProgress(min=0, max=content_length, description='Downloading:')\n",
    "    l = wdg.Label()\n",
    "    display(wdg.HBox([p, l]))\n",
    "\n",
    "    with open(\"result.h5\", \"wb\") as f:\n",
    "        while True:\n",
    "            buffer = r.read(4096*64)\n",
    "            if len(buffer) == 0:\n",
    "                break\n",
    "            p.value += len(buffer)\n",
    "            l.value = \"%.1f%%\"%((p.value*100/content_length),)\n",
    "            f.write(buffer)\n",
    "\n",
    "    print(\"Download finished!\")\n",
    "else:\n",
    "    print('Downloading...')\n",
    "    with open(\"result.h5\", \"wb\") as f:\n",
    "        while True:\n",
    "            buffer = r.read(4096*64)\n",
    "            if len(buffer) == 0:\n",
    "                break\n",
    "            f.write(buffer)\n",
    "    print(\"Download finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T08:46:50.095534Z",
     "start_time": "2018-10-23T08:46:50.091158Z"
    }
   },
   "source": [
    "# Animation of the time serie of gridded data (README)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code and libraries needed to display the data (Optional reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T17:37:50.793661Z",
     "start_time": "2019-01-14T17:37:50.788935Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('animation', embed_limit=2**31)\n",
    "plt.rc('animation', ffmpeg_path='/opt/anaconda/envs/armines-pilot/bin/ffmpeg')\n",
    "plt.rc('animation', writer='ffmpeg_file')\n",
    "plt.rc('animation', codec='vp9')\n",
    "%matplotlib inline\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.feature import NaturalEarthFeature, COLORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T17:37:51.012121Z",
     "start_time": "2019-01-14T17:37:51.006404Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define cartopy features:\n",
    "resolution = \"50m\"\n",
    "BORDERS = NaturalEarthFeature('cultural', 'admin_0_boundary_lines_land',\n",
    "                              resolution, edgecolor='black', facecolor='none')\n",
    "STATES = NaturalEarthFeature('cultural', 'admin_1_states_provinces_lakes',\n",
    "                             resolution, edgecolor='black', facecolor='none')\n",
    "COASTLINE = NaturalEarthFeature('physical', 'coastline', resolution,\n",
    "                                edgecolor='black', facecolor='none')\n",
    "LAKES = NaturalEarthFeature('physical', 'lakes', resolution,\n",
    "                            edgecolor='face',\n",
    "                            facecolor=COLORS['water'])\n",
    "LAND = NaturalEarthFeature('physical', 'land', resolution,\n",
    "                           edgecolor='face',\n",
    "                           facecolor=COLORS['land'], zorder=-1)\n",
    "OCEAN = NaturalEarthFeature('physical', 'ocean', resolution,\n",
    "                            edgecolor='face',\n",
    "                            facecolor=COLORS['water'], zorder=-1)\n",
    "RIVERS = NaturalEarthFeature('physical', 'rivers_lake_centerlines', resolution,\n",
    "                             edgecolor=COLORS['water'],\n",
    "                             facecolor='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T09:06:58.799013Z",
     "start_time": "2018-10-23T09:06:58.796397Z"
    }
   },
   "source": [
    "### Quickview of the variability in space and in time of the solar resource within the selected period (REAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Click on the > play button below to run the animation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T17:38:23.117286Z",
     "start_time": "2019-01-14T17:37:52.373500Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load downloaded data in notebook:\n",
    "hf = h5py.File('result.h5', 'r') \n",
    "\n",
    "# Create animation:\n",
    "extent = [inputs[\"left_lon\"].value, inputs[\"right_lon\"].value, inputs[\"bot_lat\"].value, inputs[\"top_lat\"].value]\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(11, 7), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "im = np.zeros((2,2), dtype='object')\n",
    "cb = np.zeros((2,2), dtype='object')\n",
    "ne = np.array([['G', 'B'], ['Gc', 'Bc']])\n",
    "\n",
    "for a, b in product(range(2), range(2)):\n",
    "    name = ne[a,b]\n",
    "    data = hf[name][:,:,:]\n",
    "    xmax = np.max(data[np.isfinite(data)])\n",
    "    im[a,b] = ax[a,b].imshow(hf[name][0,:,:], animated=True, vmin=0, vmax=xmax, origin='lower', transform=ccrs.PlateCarree(), extent=extent)\n",
    "    ax[a,b].set_title(\"%s, frame: %d\"%(name, 0))\n",
    "    ax[a,b].add_feature(BORDERS)\n",
    "    ax[a,b].add_feature(COASTLINE)\n",
    "    cb[a,b] = fig.colorbar(im[a,b], ax=ax[a,b], shrink=0.7)\n",
    "    cb[a,b].set_label(r'$W/m^{2}$', size='large')\n",
    "\n",
    "def updatefig(frame, *args):\n",
    "    global im, hf, ax\n",
    "    for a, b in product(range(2), range(2)):\n",
    "        name = ne[a,b]\n",
    "        ax[a,b].set_title(\"%s, frame: %d\"%(name, frame))\n",
    "        im[a,b].set_data(hf[name][frame, :, :])\n",
    "    return im[0,0], im[0,1], im[1,0], im[1,1]\n",
    "\n",
    "ani = animation.FuncAnimation(fig, updatefig, frames=range(inputs[\"count\"].value), interval=200, blit=True)\n",
    "\n",
    "ani.save(\"video.webm\", codec='vp9', bitrate=2000000)\n",
    "plt.close(fig) # Avoid figure to be drawn twice\n",
    "\n",
    "# Show the video\n",
    "HTML(\"\"\"\n",
    "<video controls autoplay>\n",
    "  <source src=\"video.webm\" type=\"video/webm\">\n",
    "</video>\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:armines-pilot]",
   "language": "python",
   "name": "conda-env-armines-pilot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
